{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "logistic_regression_b.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0hGzB7zHoMm"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords,wordnet\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "import string\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx-gdX-PHoMr",
        "outputId": "fd9c4ae1-e489-49e2-d62d-140174816efe"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLSmK9PXHoMu",
        "outputId": "2431dbf7-0442-452b-bea0-981a7f4dd302"
      },
      "source": [
        "dataset=pd.read_csv('SMSSpamCollection',sep='\\t',header=None,names=['LABEL','TEXT'])\n",
        "print(dataset.shape)\n",
        "dataset.drop_duplicates(inplace=True)\n",
        "print(dataset.shape)\n",
        "map={\"ham\":0,\"spam\":1}\n",
        "dataset['LABEL']=dataset['LABEL'].apply(lambda a:map.get(a) if a in map else a)\n",
        "print(dataset.head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5572, 2)\n",
            "(5169, 2)\n",
            "   LABEL                                               TEXT\n",
            "0      0  Go until jurong point, crazy.. Available only ...\n",
            "1      0                      Ok lar... Joking wif u oni...\n",
            "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      0  U dun say so early hor... U c already then say...\n",
            "4      0  Nah I don't think he goes to usf, he lives aro...\n",
            "5      1  FreeMsg Hey there darling it's been 3 week's n...\n",
            "6      0  Even my brother is not like to speak with me. ...\n",
            "7      0  As per your request 'Melle Melle (Oru Minnamin...\n",
            "8      1  WINNER!! As a valued network customer you have...\n",
            "9      1  Had your mobile 11 months or more? U R entitle...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFxhEO6JHoMv",
        "outputId": "940cc271-f790-4562-8bc5-c63cd09ad941"
      },
      "source": [
        "lemmatizer=WordNetLemmatizer()\n",
        "wordnet_map={\"N\":wordnet.NOUN,\"V\":wordnet.VERB,\"J\":wordnet.ADJ,\"R\":wordnet.ADV}\n",
        "def process_text(text):\n",
        "    text=text.lower() \n",
        "    words=[word for word in text if word not in string.punctuation]\n",
        "    words=''.join(words)\n",
        "    words=[word for word in words.split() if len(word)>2 and word.isalpha() and word not in stopwords.words('english')\n",
        "    lemmatized_words=[lemmatizer.lemmatize(word) for word in words]\n",
        "    return lemmatized_words\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "text_count_transform= CountVectorizer(analyzer=process_text)\n",
        "text_count=text_count_transform.fit_transform(dataset['TEXT'])\n",
        "print(len(text_count_transform.vocabulary_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6U6J7GlHoMw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(text_count.toarray(), dataset['LABEL'], test_size = 0.20, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32zBUa63HoMw"
      },
      "source": [
        "X_train=np.array(X_train)\n",
        "X_test=np.array(X_test)\n",
        "y_train=np.array(y_train).reshape((y_train.shape[0],1))\n",
        "y_test=np.array(y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWRrMNGTHoMx",
        "outputId": "54e3a923-723b-4ee9-b25c-0cadc14fec19"
      },
      "source": [
        "def add_ones(x):\n",
        "  ones_array=np.ones((x.shape[0],1))\n",
        "  return np.concatenate((ones_array,x),axis=1)\n",
        "\n",
        "class LogisticRegressionUsingGD:\n",
        "\n",
        "    def sigmoid(self,x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def net_input(self,theta, x):\n",
        "        return np.dot(x, theta)\n",
        "\n",
        "    def probability(self, theta, x):\n",
        "        return self.sigmoid(self.net_input(theta, x))\n",
        "\n",
        "    def cost_function(self, theta, x, y):\n",
        "        m = x.shape[0]\n",
        "        total_cost = -(1 / m) * np.sum(\n",
        "            y * np.log(self.probability(theta, x)) + (1 - y) * np.log(\n",
        "                1 - self.probability(theta, x)))\n",
        "        return total_cost\n",
        "\n",
        "    def gradient(self, theta, x, y):\n",
        "        m = x.shape[0]\n",
        "        return (1 / m) * np.dot(x.T, self.sigmoid(self.net_input(theta, x)) - y)\n",
        "\n",
        "    def fit(self, x, y, w,rate,num_iter):\n",
        "        for i in range(num_iter):\n",
        "            z=x@w\n",
        "            sigmoid=1/(1+np.exp(-z))\n",
        "            n= x.shape[0]\n",
        "            gradient= (1 / n) * (x.T@(sigmoid-y))\n",
        "            w-=(rate*gradient)\n",
        "            '''if(abs(gradient).all()<0.0000001):\n",
        "                print(\"................\")\n",
        "                print(i)\n",
        "                print(w)\n",
        "                self.w_ =w\n",
        "                return self'''\n",
        "        self.w_=w\n",
        "        print(w)\n",
        "        return self\n",
        "\n",
        "    def predict(self, x):\n",
        "        theta = self.w_\n",
        "        return self.probability(theta, x)\n",
        "    \n",
        "    \n",
        "\n",
        "    def accuracy(self, x, actual_classes, probab_threshold=0.5):\n",
        "        predicted_classes = (self.predict(x) >= probab_threshold).astype(int)\n",
        "        predicted_classes = predicted_classes.flatten()\n",
        "        accuracy = np.mean(predicted_classes == actual_classes)\n",
        "        print(predicted_classes)\n",
        "        print(actual_classes)\n",
        "        true_actual_predicted_true=0\n",
        "        true_actual_predicted_false=0\n",
        "        false_actual_predicted_true=0\n",
        "        false_actual_predicted_false=0\n",
        "        true_actual=0\n",
        "        false_actual=0\n",
        "        for i in range(len(predicted_classes)):\n",
        "            if actual_classes[i]==1:\n",
        "                true_actual+=1\n",
        "            if actual_classes[i]==0:\n",
        "                false_actual+=1\n",
        "            if actual_classes[i]==1 and predicted_classes[i]==1:\n",
        "                true_actual_predicted_true+=1\n",
        "            if actual_classes[i]==1 and predicted_classes[i]==0:\n",
        "                true_actual_predicted_false+=1\n",
        "            if actual_classes[i]==0 and predicted_classes[i]==1:\n",
        "                false_actual_predicted_true+=1\n",
        "            if actual_classes[i]==0 and predicted_classes[i]==0:\n",
        "                false_actual_predicted_false+=1\n",
        "        print(true_actual,true_actual_predicted_true,true_actual_predicted_false)\n",
        "        print(false_actual,false_actual_predicted_true,false_actual_predicted_false)\n",
        "        return accuracy * 100\n",
        "\n",
        "rate=0.1\n",
        "num_iter=10000\n",
        "X_train=add_ones(X_train)\n",
        "X_test=add_ones(X_test)\n",
        "w=np.zeros((X_train.shape[1],1))\n",
        "model=LogisticRegressionUsingGD()\n",
        "model.fit(X_train,y_train,w,rate,num_iter)\n",
        "y_test=np.array(y_test)\n",
        "print(\"X_train\",X_train.shape)\n",
        "print(\"X_test\",X_test.shape)\n",
        "accuracy=model.accuracy(X_train,y_train.flatten())\n",
        "print(accuracy)\n",
        "accuracy=model.accuracy(X_test,y_test)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-3.70555097]\n",
            " [-0.01358107]\n",
            " [ 0.        ]\n",
            " ...\n",
            " [ 0.21335868]\n",
            " [-0.00907212]\n",
            " [-0.01445396]]\n",
            "X_train (4135, 7034)\n",
            "X_test (1034, 7034)\n",
            "[0 0 0 ... 0 1 1]\n",
            "[0 0 0 ... 0 1 1]\n",
            "515 455 60\n",
            "3620 3 3617\n",
            "98.4764207980653\n",
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 0]\n",
            "138 116 22\n",
            "896 2 894\n",
            "97.678916827853\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}